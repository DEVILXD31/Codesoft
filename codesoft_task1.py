# -*- coding: utf-8 -*-
"""Codesoft task1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CWPqrF7d6YTTRbbADjD1KqB9eTEVEpmh
"""

# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc

# Load the dataset
data = pd.read_csv("Titanic1.csv")

# Initial exploration
print("First 5 rows of the dataset:")
print(data.head())
print("\nSummary statistics:")
print(data.describe())
print("\nData types and missing values:")
print(data.info())

# Data Preprocessing
# Handle missing values
imputer = SimpleImputer(strategy='median')
data['Age'] = imputer.fit_transform(data[['Age']])

# For 'Embarked', replace missing values with the most frequent value
data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)

# Drop 'Cabin' column due to high percentage of missing values
data.drop(columns=['Cabin'], inplace=True)

# Encode categorical variables
label_encoder = LabelEncoder()
data['Sex'] = label_encoder.fit_transform(data['Sex'])
data['Embarked'] = label_encoder.fit_transform(data['Embarked'])

# Drop unnecessary columns
data.drop(columns=['Name', 'Ticket'], inplace=True)

# Feature Engineering
# Create 'FamilySize' feature
data['FamilySize'] = data['SibSp'] + data['Parch'] + 1

# Drop original 'SibSp' and 'Parch' columns
data.drop(columns=['SibSp', 'Parch'], inplace=True)

# Define features and target variable
X = data.drop(columns=['Survived'])
y = data['Survived']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale the features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Model Building
# Logistic Regression
log_reg = LogisticRegression()
log_reg.fit(X_train, y_train)
y_pred_log_reg = log_reg.predict(X_test)
log_reg_acc = accuracy_score(y_test, y_pred_log_reg)

# Decision Tree Classifier
tree_clf = DecisionTreeClassifier()
tree_clf.fit(X_train, y_train)
y_pred_tree = tree_clf.predict(X_test)
tree_acc = accuracy_score(y_test, y_pred_tree)

# Random Forest Classifier
forest_clf = RandomForestClassifier()
forest_clf.fit(X_train, y_train)
y_pred_forest = forest_clf.predict(X_test)
forest_acc = accuracy_score(y_test, y_pred_forest)

# Confusion Matrices
fig, axes = plt.subplots(1, 3, figsize=(18, 5))
sns.heatmap(confusion_matrix(y_test, y_pred_log_reg), annot=True, fmt='d', ax=axes[0], cmap='Blues')
axes[0].set_title('Logistic Regression Confusion Matrix')
sns.heatmap(confusion_matrix(y_test, y_pred_tree), annot=True, fmt='d', ax=axes[1], cmap='Blues')
axes[1].set_title('Decision Tree Confusion Matrix')
sns.heatmap(confusion_matrix(y_test, y_pred_forest), annot=True, fmt='d', ax=axes[2], cmap='Blues')
axes[2].set_title('Random Forest Confusion Matrix')
plt.show()

# Classification Reports
print("Logistic Regression Classification Report:")
print(classification_report(y_test, y_pred_log_reg))

print("Decision Tree Classification Report:")
print(classification_report(y_test, y_pred_tree))

print("Random Forest Classification Report:")
print(classification_report(y_test, y_pred_forest))

# ROC Curves
models = {'Logistic Regression': log_reg, 'Decision Tree': tree_clf, 'Random Forest': forest_clf}
plt.figure(figsize=(10, 8))

for model_name, model in models.items():
    y_pred_prob = model.predict_proba(X_test)[:, 1]
    fpr, tpr, _ = roc_curve(y_test, y_pred_prob)
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], 'k--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curves')
plt.legend(loc='lower right')
plt.show()

# Model Evaluation and Conclusion
models = ['Logistic Regression', 'Decision Tree', 'Random Forest']
accuracies = [log_reg_acc, tree_acc, forest_acc]

# Accuracy Comparison Bar Plot
plt.figure(figsize=(8, 6))
sns.barplot(x=models, y=accuracies)
plt.ylabel('Accuracy')
plt.title('Model Accuracy Comparison')
plt.show()

for model, acc in zip(models, accuracies):
    print(f'{model} Accuracy: {acc:.4f}')